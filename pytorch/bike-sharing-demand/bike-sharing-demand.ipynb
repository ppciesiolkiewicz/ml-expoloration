{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c bike-sharing-demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "plt.rcParams['figure.figsize'] = (14.0, 10.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(preprocess = True):\n",
    "    train_df = pd.read_csv('./bike-sharing-demand/train.csv')\n",
    "    test_df = pd.read_csv('./bike-sharing-demand/test.csv')\n",
    "\n",
    "    def _add_datetime_cols(df):\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "        df['year'] = pd.DatetimeIndex(df['datetime']).year\n",
    "        df['day'] = pd.DatetimeIndex(df['datetime']).day\n",
    "        df['month'] = pd.DatetimeIndex(df['datetime']).month\n",
    "        df['hour'] = pd.DatetimeIndex(df['datetime']).hour\n",
    "        df['dayofweek'] = pd.DatetimeIndex(df['datetime']).dayofweek\n",
    "        \n",
    "        df.set_index('datetime')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _preprocess(df):\n",
    "        # drop columns which don't exist in test-set\n",
    "        cols_to_drop = ['registered', 'casual']\n",
    "        for ctd in cols_to_drop:\n",
    "            if ctd in df.columns:\n",
    "                df = df.drop(ctd, axis = 1)\n",
    "\n",
    "        if 'count' in df.columns:\n",
    "            print('Removing outliers')\n",
    "            cutoff_factor = 3\n",
    "            print('Before removal', df.shape, df['count'].mean(), df['count'].std(), df['count'].max(), df['count'].min())\n",
    "            df = df[abs(df['count'] - df['count'].mean()) < cutoff_factor*df['count'].std()]\n",
    "            df.reset_index(drop = True, inplace = True)\n",
    "            print('After removal', df.shape, df['count'].mean(), df['count'].std(), df['count'].max(), df['count'].min())\n",
    "\n",
    "            print('Log transform applied to count column')\n",
    "            df[target_col] = df[target_col].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "            \n",
    "        return df\n",
    "        \n",
    "    train_df = _add_datetime_cols(train_df)\n",
    "    test_df = _add_datetime_cols(test_df)\n",
    "\n",
    "    if preprocess:\n",
    "        train_df = _preprocess(train_df)\n",
    "        test_df = _preprocess(test_df)      \n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = load_data(preprocess=False)\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.isnull().sum(axis = 0))\n",
    "print(test_df.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(round(train_df.describe(), 2))\n",
    "\n",
    "# for s in range(1, 5):\n",
    "#     display(round(df[train_df['season'] == s].describe(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms for each column, correlation map, pairwise plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "train_df.hist(bins=15, color='magenta', edgecolor='black', grid=False)\n",
    "\n",
    "plt.figure()\n",
    "corr = train_df.corr()\n",
    "sns.heatmap(round(corr,2), annot=True)\n",
    "\n",
    "sns.pairplot(train_df[['count', 'temp', 'atemp', 'hour', 'year']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore target variable\n",
    "\n",
    "- outliers\n",
    "- skewed distribution\n",
    "- log transformed distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 2, figsize=(15,6))\n",
    "train_df['count'].plot(kind = 'hist', bins=100, ax = ax[0])\n",
    "train_df['count'].plot(kind = 'box', ax = ax[1])\n",
    "\n",
    "plt.figure()\n",
    "sns.distplot(train_df['count'])\n",
    "plt.figure()\n",
    "sns.distplot(train_df['count'].apply(lambda x: np.log(x + 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Windspeed\n",
    "\n",
    "- windspeed has suspicious amonut of zeros and no values between 0 to 6\n",
    "- distribution smoothened with rolling average removes some amonut of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "sns.distplot(train_df['windspeed'])\n",
    "\n",
    "plt.figure()\n",
    "train_df[(train_df['month'] == 1) & (train_df['year'] == 2011) & (train_df['day'] < 10) & (train_df['day'] > 5)] \\\n",
    "['windspeed'].plot(kind='bar')\n",
    "\n",
    "display(train_df.groupby('windspeed')['count'].count())\n",
    "\n",
    "train_df['rolling_windspeed'] = train_df['windspeed'] + train_df['windspeed'].rolling(3, center=False, min_periods=1).mean()\n",
    "plt.figure()\n",
    "sns.distplot(train_df['rolling_windspeed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Month == season "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.barplot('year', 'count', hue='season', data=train_df, ci=None)\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot('year', 'count', hue='month', data=train_df, ci=None)\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot('workingday', 'count', hue='hour', data=train_df, ci=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check high correlation between temp and atemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.jointplot(x='temp', y='atemp', data=train_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='month', y='count', data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='month', y='count', data=train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "valid_vs = 4096\n",
    "test_size = 0.2\n",
    "\n",
    "target_col = ['count']\n",
    "cont_cols = ['windspeed', 'humidity', 'temp']\n",
    "cat_cols = ['holiday', 'workingday', 'year', 'weather', 'month', 'dayofweek', 'hour']\n",
    "\n",
    "train_df, test_df = load_data()\n",
    "\n",
    "def one_hot_encode(df, cat_cols):\n",
    "    cat_cols_one_hot = []\n",
    "    for col in cat_cols:\n",
    "        one_hot = pd.get_dummies(df[col], prefix=col)\n",
    "        cat_cols_one_hot.append(one_hot.columns.tolist())\n",
    "        df = df.drop(col, axis = 1)\n",
    "        df = df.join(one_hot)\n",
    "        \n",
    "    return df, cat_cols_one_hot\n",
    "\n",
    "def normalize(df, cont_cols, normalization_params = None):\n",
    "    if normalization_params:\n",
    "        std = normalization_params['std']\n",
    "        mean = normalization_params['mean']\n",
    "    else:\n",
    "        std = df[cont_cols].std()\n",
    "        mean = df[cont_cols].mean()\n",
    "\n",
    "    df[cont_cols] = (df[cont_cols] - mean) / std\n",
    "    \n",
    "    return df, { \"mean\": mean, \"std\": std }\n",
    "\n",
    "def delog(x):\n",
    "    x = x.numpy().squeeze()\n",
    "    x = np.clip(np.e**x - 1, 0, None)\n",
    "    return x\n",
    "\n",
    "def select_features(df, cont_cols, cat_cols_one_hot):\n",
    "    feature_cols = cont_cols + [item for sublist in cat_cols_one_hot for item in sublist]\n",
    "\n",
    "    return df[feature_cols]\n",
    "\n",
    "train_df, cat_cols_one_hot = one_hot_encode(train_df, cat_cols)\n",
    "test_df, cat_cols_one_hot = one_hot_encode(test_df, cat_cols)\n",
    "train_df, normalization_params = normalize(train_df, cont_cols)\n",
    "test_df, normalization_params = normalize(test_df, cont_cols, normalization_params)\n",
    "\n",
    "train_features_df = select_features(train_df, cont_cols, cat_cols_one_hot)\n",
    "train_target_df = train_df[target_col]\n",
    "\n",
    "test_features_df = select_features(test_df, cont_cols, cat_cols_one_hot)\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_features_df, train_target_df, test_size=test_size)\n",
    "x_train_tensor = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "x_valid_tensor = torch.tensor(x_valid.values, dtype=torch.float32)\n",
    "y_valid_tensor = torch.tensor(y_valid.values, dtype=torch.float32)\n",
    "\n",
    "x_test_tensor = torch.tensor(test_features_df.values, dtype=torch.float32)\n",
    "\n",
    "train_data = data_utils.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = data_utils.DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_data = data_utils.TensorDataset(x_valid_tensor, y_valid_tensor)\n",
    "valid_loader = data_utils.DataLoader(valid_data, batch_size=valid_vs, shuffle=True)\n",
    "\n",
    "print(x_train.shape, x_valid.shape, y_train.shape, y_valid.shape, x_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_target_df.describe())\n",
    "train_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb_config = []\n",
    "        self.cat_cols_one_hot = cat_cols_one_hot\n",
    "        self.cont_cols = cont_cols\n",
    "        \n",
    "        self.emb_sizes = []\n",
    "\n",
    "        for c in cat_cols_one_hot:\n",
    "            name = c[0].split('_')[0]\n",
    "            in_features = len(c)\n",
    "            out_features = math.ceil(len(c)/2)+1\n",
    "            \n",
    "            self.emb_sizes.append(out_features)\n",
    "            self.emb_config.append({\n",
    "                \"name\": name,\n",
    "                \"out_features\": out_features,\n",
    "                \"in_features\": in_features,\n",
    "            })\n",
    "\n",
    "            setattr(self, name, nn.Sequential(\n",
    "                nn.Linear(in_features, out_features)\n",
    "            ))\n",
    "            \n",
    "        head_input_features = sum(self.emb_sizes) + len(cont_cols)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(head_input_features),\n",
    "            nn.Linear(head_input_features, 64),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        ) \n",
    "    \n",
    "        \n",
    "        for n, l in self.named_parameters():\n",
    "            if l.dim() == 1:\n",
    "                nn.init.constant_(l, 0.01)\n",
    "            else:\n",
    "                nn.init.kaiming_uniform_(l, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb_in_features_count = 0 \n",
    "        emb_output = []\n",
    "\n",
    "        for config in self.emb_config:\n",
    "            emb_layer = getattr(self, config['name'])\n",
    "            start = emb_in_features_count\n",
    "            end = emb_in_features_count + config['in_features']\n",
    "            emb_x = x[:, start:end]\n",
    "            \n",
    "            emb_output.append(emb_layer(emb_x))\n",
    "            emb_in_features_count += config['in_features']\n",
    "        \n",
    "        x = torch.cat(emb_output + [x[:, end:]], dim=1)\n",
    "        x = self.head(x)\n",
    "        \n",
    "        return x * 8 # limit the network output\n",
    "\n",
    "model = Model()\n",
    "loss_fn = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESET_TRAINING_STATS = True\n",
    "epochs = 25\n",
    "lr = 1e-4\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "lrs = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-2)\n",
    "\n",
    "if RESET_TRAINING_STATS:\n",
    "    training_stats = pd.DataFrame({\n",
    "        \"epoch\": [],\n",
    "        \"lr\": [],\n",
    "        \"train_loss\": [],\n",
    "        \"valid_loss\": [],\n",
    "        \"r2\": []\n",
    "    })\n",
    "    training_stats.set_index('epoch')\n",
    "\n",
    "prev_lr_idx = -1\n",
    "for epoch in range(epochs):\n",
    "    lr_idx = int(epoch/epochs*len(lrs))\n",
    "\n",
    "    if lr_idx != prev_lr_idx:\n",
    "        lr = lrs[lr_idx]\n",
    "        prev_lr_idx = lr_idx\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    \n",
    "    for batch_no, (xt, yt) in enumerate(train_loader):\n",
    "        yt_hat = model(xt)\n",
    "        loss = loss_fn(yt_hat, yt)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        \n",
    "    if epoch % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            for xv, yv in valid_loader:\n",
    "                yv_hat = model(xv)\n",
    "                valid_loss = loss_fn(yv_hat, yv)\n",
    "                valid_r2 = sklearn.metrics.r2_score(yv, yv_hat)\n",
    "\n",
    "            model.train()\n",
    "\n",
    "    training_stats = training_stats.append(pd.DataFrame({\n",
    "        \"epoch\": [epoch],\n",
    "        \"lr\": [lr],\n",
    "        \"train_loss\": [loss.item()],\n",
    "        \"valid_loss\": [valid_loss.item()],\n",
    "        \"r2\": [valid_r2]\n",
    "    }), sort=False)\n",
    "    \n",
    "print(training_stats)\n",
    "    \n",
    "if len(training_stats) > 1:\n",
    "    training_stats.plot(kind='line', x='epoch', y=['train_loss', 'valid_loss'], ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    for xv, yv in valid_loader:\n",
    "        yv_hat = model(xv)\n",
    "        loss = loss_fn(yv_hat, yv)\n",
    "        print('valid_loss: ', loss.item())\n",
    "        print('r2: ', sklearn.metrics.r2_score(yv, yv_hat))\n",
    "\n",
    "    yv_hat = yv_hat.numpy()\n",
    "    yv = yv.numpy()\n",
    "\n",
    "    print(yv.shape, yv_hat.shape)\n",
    "\n",
    "    df = pd.DataFrame(data=np.concatenate([yv_hat, yv, (yv_hat - yv)**2], axis = 1))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sumbission (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_hat = model(x_test_tensor)\n",
    "    y_hat = delog(y_hat)\n",
    "    df = pd.DataFrame(data = {\"datetime\": test_df['datetime'], \"count\": y_hat })\n",
    "    \n",
    "df.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c bike-sharing-demand -f submission.csv -m \"log transfomed target, trained with valid, fixed inverse log transform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
