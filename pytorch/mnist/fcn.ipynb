{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN(\n",
       "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FCN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 --\n",
      "tensor(0.1316, grad_fn=<NllLossBackward>)\n",
      "(90.05, 9005, 10000)\n",
      "Epoch 1 --\n",
      "tensor(0.0536, grad_fn=<NllLossBackward>)\n",
      "(93.86, 9386, 10000)\n",
      "Epoch 2 --\n",
      "tensor(0.0358, grad_fn=<NllLossBackward>)\n",
      "(94.92, 9492, 10000)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "epochs = 3\n",
    "\n",
    "\n",
    "def calc_acc(model, dataset):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for xb,yb in dataset:\n",
    "        yb_hat = model(xb)\n",
    "        yb_hat = torch.argmax(yb_hat, dim=-1)\n",
    "\n",
    "        correct += (yb == yb_hat).sum().item()\n",
    "        total += yb_hat.size()[0]\n",
    "                \n",
    "    return round(correct/total*100, 3), correct, total\n",
    "\n",
    "print('starting accuracy', calc_acc(model, testset))\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for xb,yb in testset:\n",
    "        model.zero_grad()\n",
    "        output = model(xb)\n",
    "        loss = F.nll_loss(output, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch} --\")\n",
    "    print(loss.item())\n",
    "    print(calc_acc(model, testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IDX = 8\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb,yb in testset:\n",
    "        x = xb[IDX]\n",
    "        y = yb[IDX]\n",
    "        y_hat = model(x)\n",
    "        y_hat = torch.argmax(y_hat)\n",
    "\n",
    "        plt.imshow(xb[IDX].view(28, 28))\n",
    "        plt.title(f\"y_hat={y_hat}, y={y}\")\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.contrib.handlers.tensorboard_logger import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "epochs = 3\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3f)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "metrics = {\"accuracy\": Accuracy(), \"loss\": Loss(criterion)}\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion)\n",
    "train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "validation_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def compute_metrics(engine):\n",
    "    train_evaluator.run(trainset)\n",
    "    validation_evaluator.run(testset)\n",
    "\n",
    "tb_logger = TensorboardLogger(log_dir='/home/asdf/tensorboard')\n",
    "\n",
    "tb_logger.attach(\n",
    "    trainer,\n",
    "    log_handler=OutputHandler(\n",
    "        tag=\"training\", output_transform=lambda loss: {\"batchloss\": loss}, metric_names=\"all\"\n",
    "    ),\n",
    "    event_name=Events.ITERATION_COMPLETED(every=100),\n",
    ")\n",
    "\n",
    "tb_logger.attach(\n",
    "    train_evaluator,\n",
    "    log_handler=OutputHandler(tag=\"training\", metric_names=[\"loss\", \"accuracy\"], another_engine=trainer),\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    ")\n",
    "\n",
    "tb_logger.attach(\n",
    "    validation_evaluator,\n",
    "    log_handler=OutputHandler(tag=\"validation\", metric_names=[\"loss\", \"accuracy\"], another_engine=trainer),\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    ")\n",
    "\n",
    "tb_logger.attach(\n",
    "    trainer, log_handler=OptimizerParamsHandler(optimizer), event_name=Events.ITERATION_COMPLETED(every=100)\n",
    ")\n",
    "\n",
    "tb_logger.attach(trainer, log_handler=WeightsScalarHandler(model), event_name=Events.ITERATION_COMPLETED(every=100))\n",
    "\n",
    "tb_logger.attach(trainer, log_handler=WeightsHistHandler(model), event_name=Events.EPOCH_COMPLETED(every=100))\n",
    "\n",
    "tb_logger.attach(trainer, log_handler=GradsScalarHandler(model), event_name=Events.ITERATION_COMPLETED(every=100))\n",
    "\n",
    "tb_logger.attach(trainer, log_handler=GradsHistHandler(model), event_name=Events.EPOCH_COMPLETED(every=100))\n",
    "\n",
    "trainer.run(trainset, max_epochs=epochs)\n",
    "tb_logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
